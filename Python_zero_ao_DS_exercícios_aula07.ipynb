{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T20:51:01.868148Z",
     "start_time": "2021-02-04T20:51:01.863150Z"
    }
   },
   "source": [
    "# Exercícios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T01:53:47.181317Z",
     "start_time": "2021-02-13T01:53:47.176324Z"
    }
   },
   "source": [
    "### Fazer deploy no Heroku com streamlit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T01:53:47.181317Z",
     "start_time": "2021-02-13T01:53:47.176324Z"
    }
   },
   "source": [
    "#### link do deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link para acessar ao deploy realizado\n",
    "https://house-rocket-app.herokuapp.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T01:53:47.181317Z",
     "start_time": "2021-02-13T01:53:47.176324Z"
    }
   },
   "source": [
    "#### dashboard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name: dashboard.py\n",
    "# Código pronto para colar no PyCharm e plotar o mapa com streamlit\n",
    "\n",
    "import geopandas\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "\n",
    "from streamlit_folium import folium_static\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "st.set_page_config( layout='wide' )\n",
    "\n",
    "\n",
    "@st.cache( allow_output_mutation=True )\n",
    "def get_data( path ):\n",
    "    data = pd.read_csv( path )\n",
    "\n",
    "    return data\n",
    "\n",
    "@st.cache( allow_output_mutation=True )\n",
    "def get_geofile( url ):\n",
    "    geofile = geopandas.read_file( url )\n",
    "\n",
    "    return geofile\n",
    "\n",
    "def set_feature ( data ):\n",
    "    # add new features\n",
    "    data['price_m2'] = data['price'] / data['sqft_lot']\n",
    "\n",
    "    return data\n",
    "\n",
    "def overview_data( data ):\n",
    "    f_attributes = st.sidebar.multiselect('Enter columns', data.columns)\n",
    "    f_zipcode = st.sidebar.multiselect(\n",
    "        'Enter zipcode',\n",
    "        data['zipcode'].unique())\n",
    "\n",
    "    st.title('Data Overview')\n",
    "\n",
    "    if (f_zipcode != []) & (f_attributes != []):\n",
    "        data = data.loc[data['zipcode'].isin(f_zipcode), f_attributes]\n",
    "    elif (f_zipcode != []) & (f_attributes == []):\n",
    "        data = data.loc[data['zipcode'].isin(f_zipcode), :]\n",
    "    elif (f_zipcode == []) & (f_attributes != []):\n",
    "        data = data.loc[:, f_attributes]\n",
    "    else:\n",
    "        data = data.copy()\n",
    "\n",
    "    st.dataframe(data.head())\n",
    "\n",
    "    c1, c2 = st.beta_columns((1, 1))\n",
    "    # Average metrics\n",
    "    df1 = data[['id', 'zipcode']].groupby('zipcode').count().reset_index()\n",
    "    df2 = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "    df3 = data[['sqft_living', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "    df4 = data[['price_m2', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "\n",
    "    # merge\n",
    "    m1 = pd.merge(df1, df2, on='zipcode', how='inner')\n",
    "    m2 = pd.merge(m1, df3, on='zipcode', how='inner')\n",
    "    df = pd.merge(m2, df4, on='zipcode', how='inner')\n",
    "    # definindo o nome das colunas\n",
    "    df.columns = ['ZIPCODE', 'TOTAL HOUSES', 'PRICE', 'SQFT LIVING', 'PRICE/M2']\n",
    "\n",
    "    c1.header('Average Values')\n",
    "    c1.dataframe(df, height=600)\n",
    "\n",
    "    # Statistic Descriptive\n",
    "    num_attributes = data.select_dtypes(include=['int64', 'float64'])\n",
    "    media = pd.DataFrame(num_attributes.apply(np.mean))\n",
    "    mediana = pd.DataFrame(num_attributes.apply(np.median))\n",
    "    std = pd.DataFrame(num_attributes.apply(np.std))\n",
    "\n",
    "    max_ = pd.DataFrame(num_attributes.apply(np.max))\n",
    "    min_ = pd.DataFrame(num_attributes.apply(np.min))\n",
    "\n",
    "    df1 = pd.concat([max_, min_, media, mediana, std], axis=1).reset_index()\n",
    "\n",
    "    df1.columns = ['attributes', 'max', 'min', 'mean', 'median', 'std']\n",
    "    c2.header('Descriptive Analysis')\n",
    "    c2.dataframe(df1, height=800)\n",
    "\n",
    "    return None\n",
    "\n",
    "def portfolio_density( data, geofile ):\n",
    "    st.title('Region Overview')\n",
    "\n",
    "    c1, c2 = st.beta_columns((1, 1))\n",
    "    c1.header('Portfolio Desity')\n",
    "\n",
    "    df = data.sample(10)\n",
    "\n",
    "    # Base Map - Folium\n",
    "    density_map = folium.Map(location=[data['lat'].mean(),\n",
    "                                       data['long'].mean()],\n",
    "                             default_zoom_start=15)\n",
    "\n",
    "    marker_cluster = MarkerCluster().add_to(density_map)\n",
    "    for name, row in df.iterrows():\n",
    "        folium.Marker([row['lat'], row['long']],\n",
    "                      popup='Sold R${0} on: {1}. Features: {2} sqft, {3} bedrooms, {4} bathrooms, year built: {5}'.format(\n",
    "                          row['price'],\n",
    "                          row['date'],\n",
    "                          row['sqft_living'],\n",
    "                          row['bedrooms'],\n",
    "                          row['bathrooms'],\n",
    "                          row['yr_built'])).add_to(marker_cluster)\n",
    "\n",
    "    with c1:\n",
    "        folium_static(density_map)\n",
    "\n",
    "    # Region Price Map\n",
    "    c2.header('Price Density')\n",
    "\n",
    "    df = data[['price', 'zipcode']].groupby('zipcode').mean().reset_index()\n",
    "    df.columns = ['ZIP', 'PRICE']\n",
    "\n",
    "    # df = df.sample( 10 )\n",
    "\n",
    "    geofile = geofile[geofile['ZIP'].isin(df['ZIP'].tolist())]\n",
    "\n",
    "    region_price_map = folium.Map(location=[data['lat'].mean(),\n",
    "                                            data['long'].mean()],\n",
    "                                  default_zoom_start=15)\n",
    "\n",
    "    region_price_map.choropleth(data=df,\n",
    "                                geo_data=geofile,\n",
    "                                columns=['ZIP', 'PRICE'],\n",
    "                                key_on='feature.properties.ZIP',\n",
    "                                fill_color='YlOrRd',\n",
    "                                fill_opacity=0.7,\n",
    "                                line_opacity=0.2,\n",
    "                                legend_name='AVG PRICE')\n",
    "\n",
    "    with c2:\n",
    "        folium_static(region_price_map)\n",
    "\n",
    "        return None\n",
    "\n",
    "def commercial_distribution( data ):\n",
    "    st.sidebar.title('Commercial Options')\n",
    "    st.title(' Commercial Attributes')\n",
    "\n",
    "    # ---------- Average Price per Year\n",
    "\n",
    "    data['date'] = pd.to_datetime(data['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # filters\n",
    "    min_year_built = int(data['yr_built'].min())\n",
    "    max_year_built = int(data['yr_built'].max())\n",
    "\n",
    "    st.sidebar.subheader('Select Max Year Built')\n",
    "    f_year_built = st.sidebar.slider('Year Built', min_year_built,  # min\n",
    "                                     max_year_built,  # max\n",
    "                                     min_year_built)  # default\n",
    "    st.header('Average Price per Year built')\n",
    "\n",
    "    # data selection\n",
    "    df = data.loc[data['yr_built'] < f_year_built]\n",
    "    df = df[['yr_built', 'price']].groupby('yr_built').mean().reset_index()\n",
    "\n",
    "    # plot\n",
    "    fig = px.line(df, x='yr_built', y='price')\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ---------- Average Price per Day\n",
    "    st.header('Average Price per day')\n",
    "    st.sidebar.subheader('Select Max Date')\n",
    "\n",
    "    # filters\n",
    "    min_date = datetime.strptime(data['date'].min(), '%Y-%m-%d')\n",
    "    max_date = datetime.strptime(data['date'].max(), '%Y-%m-%d')\n",
    "\n",
    "    f_date = st.sidebar.slider('Date', min_date, max_date, min_date)\n",
    "\n",
    "    # data filtering\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    df = data.loc[data['date'] < f_date]\n",
    "    df = df[['date', 'price']].groupby('date').mean().reset_index()\n",
    "\n",
    "    # plot\n",
    "    fig = px.line(df, x='date', y='price')\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ------------------- Histograma\n",
    "    st.header('Price Distribution')\n",
    "    st.sidebar.subheader('Select Max Price')\n",
    "\n",
    "    # filter\n",
    "    min_price = int(data['price'].min())\n",
    "    max_price = int(data['price'].max())\n",
    "    avg_price = int(data['price'].mean())\n",
    "\n",
    "    # data filtering\n",
    "    f_price = st.sidebar.slider('Price', min_price, max_price, avg_price)\n",
    "    df = data.loc[data['price'] < f_price]\n",
    "\n",
    "    # data plot\n",
    "    fig = px.histogram(df, x='price', nbins=50)\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    return None\n",
    "\n",
    "def attributes_distribution( data ):\n",
    "    st.sidebar.title('Attributes Options')\n",
    "    st.title('House Attributes')\n",
    "\n",
    "    # filters\n",
    "    f_bedrooms = st.sidebar.selectbox('Max number of bedrooms',\n",
    "                                      sorted(set(data['bedrooms'].unique())))\n",
    "\n",
    "    f_bathrooms = st.sidebar.selectbox('Max number of bathrooms',\n",
    "                                       sorted(set(data['bathrooms'].unique())))\n",
    "\n",
    "    c1, c2 = st.beta_columns(2)\n",
    "\n",
    "    # House per bedrooms\n",
    "    c1.header('Houses per bedrooms')\n",
    "    df = data[data['bedrooms'] < f_bedrooms]\n",
    "    fig = px.histogram(df, x='bedrooms', nbins=19)\n",
    "    c1.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # House per bathrooms\n",
    "    c2.header('Houses per bathrooms')\n",
    "    df = data[data['bathrooms'] < f_bathrooms]\n",
    "    fig = px.histogram(data, x='bathrooms', nbins=19)\n",
    "    c2.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # filters\n",
    "    f_floors = st.sidebar.selectbox('Max number of floor',\n",
    "                                    sorted(set(data['floors'].unique())))\n",
    "\n",
    "    f_waterview = st.sidebar.checkbox('Only Houses with Water View')\n",
    "\n",
    "    c1, c2 = st.beta_columns(2)\n",
    "\n",
    "    # House per floors\n",
    "    c1.header('Houses per floor')\n",
    "    df = data[data['floors'] < f_floors]\n",
    "\n",
    "    # plot\n",
    "    fig = px.histogram(data, x='floors', nbins=19)\n",
    "    c1.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # House per water view\n",
    "    if f_waterview:\n",
    "        df = data[data['waterfront'] == 1]\n",
    "    else:\n",
    "        df = data.copy()\n",
    "    fig = px.histogram(df, x='waterfront', nbins=10)\n",
    "    c2.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ETL\n",
    "    # data extraction\n",
    "    # get data\n",
    "    path = 'kc_house_data.csv'\n",
    "    url = 'https://opendata.arcgis.com/datasets/83fc2e72903343aabff6de8cb445b81c_2.geojson'\n",
    "\n",
    "    data = get_data( path )\n",
    "    geofile = get_geofile( url )\n",
    "\n",
    "    # transformation\n",
    "    data = set_feature ( data )\n",
    "\n",
    "    overview_data( data )\n",
    "\n",
    "    portfolio_density( data, geofile )\n",
    "\n",
    "    commercial_distribution( data )\n",
    "\n",
    "    attributes_distribution( data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T01:53:47.181317Z",
     "start_time": "2021-02-13T01:53:47.176324Z"
    }
   },
   "source": [
    "#### Procfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name: Procfile\n",
    "# Código que deve ser salvo neste arquivo chamado Procfile\n",
    "web: sh setup.sh && streamlit run dashboard.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T01:53:47.181317Z",
     "start_time": "2021-02-13T01:53:47.176324Z"
    }
   },
   "source": [
    "#### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name: requirements.txt\n",
    "# Bibliotecas que devem ser salvas neste arquivo chamado requirements.txt\n",
    "folium==0.11.0\n",
    "geopandas==0.8.2\n",
    "numpy==1.19.5\n",
    "pandas==1.1.5\n",
    "plotly==4.14.3\n",
    "streamlit==0.76.0\n",
    "streamlit-folium==0.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T01:53:47.181317Z",
     "start_time": "2021-02-13T01:53:47.176324Z"
    }
   },
   "source": [
    "#### setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name: setup.sh\n",
    "# Código que deve ser salvo neste arquivo chamado setup.sh\n",
    "mkdir -p ~/.streamlit/\n",
    "\n",
    "echo \"\\\n",
    "[general]\\n\\\n",
    "email = \\\"marlon.muller@outlook.com\\\"\\n\\\n",
    "\" > ~/.streamlit/credentials.toml\n",
    "\n",
    "echo \"\\\n",
    "[server]\\n\\\n",
    "headless = true\\n\\\n",
    "enableCORS=false\\n\\\n",
    "port = $PORT\\n\\\n",
    "\" > ~/.streamlit/config.toml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
